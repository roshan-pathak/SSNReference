{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hog\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSSNRCalculator\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates Spectral Signal-to-Noise Ratio for cryo-EM data\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "import mrcfile\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.interpolate import griddata\n",
    "import json\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import pearsonr\n",
    "from skimage.feature import hog\n",
    "import seaborn as sns\n",
    "from google.colab import files\n",
    "\n",
    "class SSNRCalculator:\n",
    "    \"\"\"Calculates Spectral Signal-to-Noise Ratio for cryo-EM data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.power_spectrum = None\n",
    "        self.noise_spectrum = None\n",
    "        \n",
    "    def calculate_power_spectrum(self, image):\n",
    "        \"\"\"\n",
    "        Calculate power spectrum of an image\n",
    "        \"\"\"\n",
    "        ft = fftpack.fft2(image)\n",
    "        ps = np.abs(ft)**2\n",
    "        return fftpack.fftshift(ps)\n",
    "    \n",
    "    def radial_average(self, data):\n",
    "        \"\"\"\n",
    "        Calculate radially averaged 1D profile from 2D data\n",
    "        \"\"\"\n",
    "        center = np.array(data.shape) // 2\n",
    "        y, x = np.indices(data.shape)\n",
    "        r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "        r = r.astype(int)\n",
    "        \n",
    "        # Average over radial bins\n",
    "        tbin = np.bincount(r.ravel(), data.ravel())\n",
    "        nr = np.bincount(r.ravel())\n",
    "        radial_profile = tbin / nr\n",
    "        return radial_profile\n",
    "    \n",
    "    def calculate_ssnr(self, particles, class_average):\n",
    "        \"\"\"\n",
    "        Calculate SSNR for a class\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        particles : ndarray\n",
    "            Stack of particle images (n_particles, height, width)\n",
    "        class_average : ndarray\n",
    "            Class average image (height, width)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        ssnr : ndarray\n",
    "            1D array of SSNR values as function of spatial frequency\n",
    "        freq : ndarray\n",
    "            Corresponding spatial frequencies\n",
    "        \"\"\"\n",
    "        # Calculate average power spectrum\n",
    "        ps_sum = np.zeros_like(self.calculate_power_spectrum(particles[0]))\n",
    "        for particle in particles:\n",
    "            ps = self.calculate_power_spectrum(particle)\n",
    "            ps_sum += ps\n",
    "        ps_avg = ps_sum / len(particles)\n",
    "        \n",
    "        # Calculate noise power spectrum\n",
    "        noise_ps_sum = np.zeros_like(ps_avg)\n",
    "        for particle in particles:\n",
    "            noise = particle - class_average\n",
    "            noise_ps = self.calculate_power_spectrum(noise)\n",
    "            noise_ps_sum += noise_ps\n",
    "        noise_ps = noise_ps_sum / len(particles)\n",
    "        \n",
    "        # Calculate radial averages\n",
    "        ps_radial = self.radial_average(ps_avg)\n",
    "        noise_ps_radial = self.radial_average(noise_ps)\n",
    "        \n",
    "        # Calculate SSNR\n",
    "        ssnr = (ps_radial - noise_ps_radial) / noise_ps_radial\n",
    "        \n",
    "        # Generate frequency axis (in 1/pixel units)\n",
    "        freq = np.fft.fftfreq(len(ssnr))[:len(ssnr)]\n",
    "        \n",
    "        return ssnr, freq\n",
    "    \n",
    "    def get_average_ssnr(self, ssnr, freq, freq_range=(0, 0.5)):\n",
    "        \"\"\"\n",
    "        Calculate average SSNR within a frequency range\n",
    "        \"\"\"\n",
    "        mask = (freq >= freq_range[0]) & (freq <= freq_range[1])\n",
    "        return np.mean(ssnr[mask])\n",
    "\n",
    "class BackProjector:\n",
    "    \"\"\"Handles 3D map back projection for comparison with 2D classes\"\"\"\n",
    "    \n",
    "    def __init__(self, volume):\n",
    "        \"\"\"\n",
    "        Initialize with 3D volume\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        volume : ndarray\n",
    "            3D volume to project\n",
    "        \"\"\"\n",
    "        self.volume = volume\n",
    "        \n",
    "    def project_volume(self, euler_angles, output_shape):\n",
    "        \"\"\"\n",
    "        Create 2D projection of 3D volume at specified orientation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        euler_angles : tuple\n",
    "            (phi, theta, psi) Euler angles in degrees\n",
    "        output_shape : tuple\n",
    "            (height, width) of desired output projection\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        ndarray\n",
    "            2D projection\n",
    "        \"\"\"\n",
    "        phi, theta, psi = euler_angles\n",
    "        \n",
    "        # Rotate volume\n",
    "        vol_rot = self.rotate_volume(self.volume, phi, theta, psi)\n",
    "        \n",
    "        # Project along Z axis\n",
    "        projection = np.sum(vol_rot, axis=2)\n",
    "        \n",
    "        # Resize to desired dimensions if needed\n",
    "        if projection.shape != output_shape:\n",
    "            y = np.linspace(0, projection.shape[0], output_shape[0])\n",
    "            x = np.linspace(0, projection.shape[1], output_shape[1])\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            \n",
    "            points = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "            values = projection.ravel()\n",
    "            \n",
    "            grid_x, grid_y = np.meshgrid(np.arange(output_shape[1]), \n",
    "                                       np.arange(output_shape[0]))\n",
    "            projection = griddata(points, values, \n",
    "                                (grid_x, grid_y), \n",
    "                                method='linear')\n",
    "            \n",
    "        return projection\n",
    "    \n",
    "    def rotate_volume(self, volume, phi, theta, psi):\n",
    "        \"\"\"\n",
    "        Apply Euler angle rotations to volume\n",
    "        \"\"\"\n",
    "        # Rotate around Z (phi)\n",
    "        vol_rot = rotate(volume, phi, axes=(1, 0), reshape=False)\n",
    "        \n",
    "        # Rotate around Y (theta)\n",
    "        vol_rot = rotate(vol_rot, theta, axes=(2, 0), reshape=False)\n",
    "        \n",
    "        # Rotate around Z again (psi)\n",
    "        vol_rot = rotate(vol_rot, psi, axes=(1, 0), reshape=False)\n",
    "        \n",
    "        return vol_rot\n",
    "    \n",
    "    def optimize_orientation(self, target_image, initial_angles=(0,0,0), \n",
    "                           angle_range=(-180,180), n_steps=10):\n",
    "        \"\"\"\n",
    "        Find optimal projection orientation to match target image\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        target_image : ndarray\n",
    "            2D image to match\n",
    "        initial_angles : tuple\n",
    "            Starting orientation\n",
    "        angle_range : tuple\n",
    "            Range of angles to search\n",
    "        n_steps : int\n",
    "            Number of steps for each angle\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            Optimal (phi, theta, psi) angles\n",
    "        float\n",
    "            Correlation at optimal orientation\n",
    "        \"\"\"\n",
    "        best_correlation = -1\n",
    "        best_angles = initial_angles\n",
    "        \n",
    "        # Grid search over angles\n",
    "        for phi in np.linspace(angle_range[0], angle_range[1], n_steps):\n",
    "            for theta in np.linspace(angle_range[0], angle_range[1], n_steps):\n",
    "                for psi in np.linspace(angle_range[0], angle_range[1], n_steps):\n",
    "                    projection = self.project_volume((phi, theta, psi), \n",
    "                                                  target_image.shape)\n",
    "                    correlation = np.corrcoef(projection.ravel(), \n",
    "                                           target_image.ravel())[0,1]\n",
    "                    \n",
    "                    if correlation > best_correlation:\n",
    "                        best_correlation = correlation\n",
    "                        best_angles = (phi, theta, psi)\n",
    "        \n",
    "        return best_angles, best_correlation\n",
    "\n",
    "class DataParser:\n",
    "    \"\"\"Handles parsing of CryoSPARC and RELION data files\"\"\"\n",
    "    def __init__(self):\n",
    "        self.class_images = None\n",
    "        self.particle_assignments = None\n",
    "        self.n_classes = None\n",
    "        self.class_particles = {}\n",
    "        \n",
    "    def parse_mrc(self, mrc_path):\n",
    "        \"\"\"Parse 2D class averages from MRC file\"\"\"\n",
    "        with mrcfile.open(mrc_path) as mrc:\n",
    "            self.class_images = mrc.data\n",
    "            if len(mrc.data.shape) == 2:\n",
    "                self.class_images = mrc.data[np.newaxis, ...]\n",
    "            self.n_classes = len(self.class_images)\n",
    "        return self.class_images\n",
    "    \n",
    "    def parse_cs_file(self, cs_path):\n",
    "        \"\"\"\n",
    "        Parse particle assignments from CryoSPARC CS file\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        cs_path : str\n",
    "            Path to the .cs file containing particle data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Dictionary mapping class IDs to lists of particle indices\n",
    "        \"\"\"\n",
    "        # Load CS file as numpy structured array\n",
    "        data = np.load(cs_path)\n",
    "        \n",
    "        # Print available fields for debugging\n",
    "        print(\"Available fields in CS file:\", data.dtype.names)\n",
    "        \n",
    "        # Extract class assignments\n",
    "        # Note: Field names might need adjustment based on your CS file structure\n",
    "        try:\n",
    "            # Try different possible field names for class assignments\n",
    "            if 'class' in data.dtype.names:\n",
    "                class_assignments = data['class']\n",
    "            elif 'class_id' in data.dtype.names:\n",
    "                class_assignments = data['class_id']\n",
    "            elif 'alignments2D/class' in data.dtype.names:\n",
    "                class_assignments = data['alignments2D/class']\n",
    "            else:\n",
    "                raise KeyError(\"Could not find class assignment field in CS file\")\n",
    "                \n",
    "            # Try different possible field names for particle IDs\n",
    "            if 'particle_id' in data.dtype.names:\n",
    "                particle_ids = data['particle_id']\n",
    "            elif 'uid' in data.dtype.names:\n",
    "                particle_ids = data['uid']\n",
    "            else:\n",
    "                # If no explicit particle IDs, use array indices\n",
    "                particle_ids = np.arange(len(class_assignments))\n",
    "                \n",
    "        except KeyError as e:\n",
    "            print(\"Available fields:\", data.dtype.names)\n",
    "            raise KeyError(f\"Error accessing fields in CS file: {e}\")\n",
    "            \n",
    "        self.particle_assignments = {pid: cid for pid, cid in zip(particle_ids, class_assignments)}\n",
    "        \n",
    "        # Group particles by class\n",
    "        unique_classes = np.unique(class_assignments)\n",
    "        self.class_particles = {i: [] for i in unique_classes}\n",
    "        \n",
    "        for pid, cid in self.particle_assignments.items():\n",
    "            self.class_particles[cid].append(pid)\n",
    "            \n",
    "        return self.class_particles\n",
    "    \n",
    "    def get_class_particles(self, class_id):\n",
    "        \"\"\"Get list of particles for a specific class\"\"\"\n",
    "        return self.class_particles.get(class_id, [])\n",
    "    \n",
    "    def get_particle_class(self, particle_id):\n",
    "        \"\"\"Get class assignment for a specific particle\"\"\"\n",
    "        return self.particle_assignments.get(particle_id, None)\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print summary of parsed data\"\"\"\n",
    "        if self.class_images is not None:\n",
    "            print(f\"Number of class averages: {self.n_classes}\")\n",
    "        \n",
    "        if self.class_particles:\n",
    "            print(\"\\nClass distribution:\")\n",
    "            for class_id, particles in self.class_particles.items():\n",
    "                print(f\"Class {class_id}: {len(particles)} particles\")\n",
    "\n",
    "class ScoreCalculator:\n",
    "    \"\"\"Calculates various scores for 2D classes\"\"\"\n",
    "    def __init__(self, class_images, reference_map):\n",
    "        self.class_images = class_images\n",
    "        self.reference_map = reference_map\n",
    "        \n",
    "    def calculate_ssnr(self, class_idx):\n",
    "      particles = self.get_particles_for_class(class_idx)\n",
    "      class_average = self.class_images[class_idx]\n",
    "      ssnr_calc = SSNRCalculator()\n",
    "      ssnr, freq = ssnr_calc.calculate_ssnr(particles, class_average)\n",
    "      return ssnr_calc.get_average_ssnr(ssnr, freq)\n",
    "        \n",
    "    def calculate_pearson_score(self, class_image, projection):\n",
    "        \"\"\"Calculate Pearson correlation between class and projection\"\"\"\n",
    "        return pearsonr(class_image.flatten(), projection.flatten())[0]\n",
    "        \n",
    "    def calculate_hog_score(self, class_image, projection):\n",
    "        \"\"\"Calculate HOG score between class and projection\"\"\"\n",
    "        class_hog = hog(class_image)\n",
    "        proj_hog = hog(projection)\n",
    "        return np.dot(class_hog, proj_hog) / (np.linalg.norm(class_hog) * np.linalg.norm(proj_hog))\n",
    "        \n",
    "    def calculate_all_scores(self):\n",
    "        \"\"\"Calculate all scores for each class\"\"\"\n",
    "        scores = []\n",
    "        for i in range(len(self.class_images)):\n",
    "            # Get projection of 3D map for this view\n",
    "            projection = self.get_projection(i)  # This needs to be implemented\n",
    "            \n",
    "            pearson = self.calculate_pearson_score(self.class_images[i], projection)\n",
    "            hog = self.calculate_hog_score(self.class_images[i], projection)\n",
    "            ssnr = self.calculate_ssnr(i)  # This needs particle data\n",
    "            \n",
    "            scores.append([pearson, hog, ssnr])\n",
    "            \n",
    "        return np.array(scores)\n",
    "\n",
    "class ClassSelector:\n",
    "    \"\"\"Handles class selection based on various criteria\"\"\"\n",
    "    def __init__(self, scores, class_particles):\n",
    "        self.scores = scores\n",
    "        self.class_particles = class_particles\n",
    "        self.clusters = None\n",
    "        \n",
    "    def select_top_k_percentile(self, k, score_idx=0):\n",
    "        \"\"\"Select top K percentile classes by specified score\"\"\"\n",
    "        threshold = np.percentile(self.scores[:, score_idx], 100-k)\n",
    "        return self.scores[:, score_idx] >= threshold\n",
    "        \n",
    "    def select_top_n(self, n, score_idx=0):\n",
    "        \"\"\"Select top N classes by specified score\"\"\"\n",
    "        indices = np.argsort(self.scores[:, score_idx])[-n:]\n",
    "        selected = np.zeros(len(self.scores), dtype=bool)\n",
    "        selected[indices] = True\n",
    "        return selected\n",
    "        \n",
    "    def select_with_ssnr_threshold(self, method, threshold, **kwargs):\n",
    "        \"\"\"Select classes using specified method and SSNR threshold\"\"\"\n",
    "        if method == 'top_n':\n",
    "            base_selection = self.select_top_n(**kwargs)\n",
    "        else:\n",
    "            base_selection = self.select_top_k_percentile(**kwargs)\n",
    "            \n",
    "        ssnr_mask = self.scores[:, 2] >= threshold\n",
    "        return base_selection & ssnr_mask\n",
    "        \n",
    "    def perform_clustering(self, eps=0.3, min_samples=5):\n",
    "        \"\"\"Perform DBSCAN clustering on score space\"\"\"\n",
    "        clustering = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        self.clusters = clustering.fit_predict(self.scores)\n",
    "        return self.clusters\n",
    "        \n",
    "    def get_particle_groups(self, selection):\n",
    "        \"\"\"Split particles into accepted and rejected groups\"\"\"\n",
    "        accepted = []\n",
    "        rejected = []\n",
    "        \n",
    "        for i, selected in enumerate(selection):\n",
    "            if selected:\n",
    "                accepted.extend(self.class_particles[i])\n",
    "            else:\n",
    "                rejected.extend(self.class_particles[i])\n",
    "                \n",
    "        return accepted, rejected\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Handles all visualization tasks\"\"\"\n",
    "    def __init__(self, scores, clusters=None):\n",
    "        self.scores = scores\n",
    "        self.clusters = clusters\n",
    "        \n",
    "    def plot_3d(self):\n",
    "        \"\"\"Create interactive 3D plot\"\"\"\n",
    "        fig = px.scatter_3d(\n",
    "            x=self.scores[:, 0],\n",
    "            y=self.scores[:, 1],\n",
    "            z=self.scores[:, 2],\n",
    "            color=self.clusters if self.clusters is not None else None,\n",
    "            labels={'x': 'Pearson Score', 'y': 'HOG Score', 'z': 'SSNR'}\n",
    "        )\n",
    "        return fig\n",
    "        \n",
    "    def plot_2d_projections(self):\n",
    "        \"\"\"Create 2D projection plots\"\"\"\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Pearson vs HOG\n",
    "        ax1.scatter(self.scores[:, 0], self.scores[:, 1])\n",
    "        ax1.set_xlabel('Pearson Score')\n",
    "        ax1.set_ylabel('HOG Score')\n",
    "        \n",
    "        # Pearson vs SSNR\n",
    "        ax2.scatter(self.scores[:, 0], self.scores[:, 2])\n",
    "        ax2.set_xlabel('Pearson Score')\n",
    "        ax2.set_ylabel('SSNR')\n",
    "        \n",
    "        # HOG vs SSNR\n",
    "        ax3.scatter(self.scores[:, 1], self.scores[:, 2])\n",
    "        ax3.set_xlabel('HOG Score')\n",
    "        ax3.set_ylabel('SSNR')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = DataParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload your particles.cs file\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m software \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcryoSPARC\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upload your particles.cs file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m   particles \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload() \n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upload your blob.cs file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m   blob \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "#@markdown Select the software package you are using:\n",
    "software = \"cryoSPARC\" #@param [\"cryoSPARC\", \"RELION\"] {type:\"string\"}\n",
    "#@markdown Now run the code cell.\n",
    "\n",
    "if software == \"cryoSPARC\":\n",
    "  print(\"Please upload your particles.cs file\")\n",
    "  particles = files.upload() \n",
    "  print(\"Please upload your blob.cs file\")\n",
    "  blob = files.upload()\n",
    "  \n",
    "  # Rename uploaded files\n",
    "  for filename, content in particles.items():\n",
    "    with open('particles.cs', 'wb') as f:\n",
    "      f.write(content)\n",
    "  for filename, content in blob.items():\n",
    "    with open('class_averages.mrc', 'wb') as f:\n",
    "      f.write(content)\n",
    "  \n",
    "  #Parser\n",
    "  class_particles = parser.parse_cs_file('particles.cs')\n",
    "  class_images = parser.parse_mrc('class_averages.mrc')\n",
    "\n",
    "elif software == \"RELION\":\n",
    "  print(\"Please upload your run_data.star file\")\n",
    "  data = files.upload()\n",
    "  \n",
    "  # Rename uploaded file\n",
    "  for filename, content in data.items():\n",
    "    with open('run_data.star', 'wb') as f:\n",
    "      f.write(content)\n",
    "\n",
    "print(\"Please upload your 3D reference map\")\n",
    "reference_map = files.upload()\n",
    "\n",
    "# Rename uploaded file\n",
    "for filename, content in reference_map.items():\n",
    "  with open('map.mrc', 'wb') as f:\n",
    "    f.write(content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
